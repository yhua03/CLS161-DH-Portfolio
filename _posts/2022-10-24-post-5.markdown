---
layout: post
title:  "NLP"
date:   "2022-10-24"
categories: jekyll update
---

## Reading Reflection 4 - *How Computers Analyze Text* ##


The article "The Measured Words: How Computers Analyze Text" looks at how advances in computer technology have made analyzing text easier and more precise than ever before. This is done through the use of natural language processing (NLP), which is a form of artificial intelligence. The article explains how computers can now scan through large amounts of text to identify patterns, extract relevant information, and even generate new insights. I personally think that the ability to process natural language and accurately interpreting human speech and conservations is an incredible and insane concept. The fact that computers now can even detect sentiment, recognize emotions, and understand sarcasm just shows how advanced the NLP technology is today. Furthermore, the article looks at how natural language processing is being used in a variety of industries, from healthcare to education, and the technology serves as an integral part of the textual analysis framework in these industries. Iâ€™ve learned that NLP enables computers to understand the meanings of words and sentences and can be used to make predictions and recommendations from text, which as mentioned above could be valuably applied in research and business. The author does an amazing job on explaining the basis of the logic behind NLP. For example, computers heavily rely on patterns and frequencies when interpreting texts. Furthermore, KWICs and Concording is another method for information analysis, which involves with the ability to skim.  Another interesting topic that I read in this chapter was about tokenization. The author defines tokenization as the process of breaking apart a text into smaller pieces that can be manipulated and counted. When you break a long string into smaller parts, it helps the computer to more easily interpret, retrieve and recombine the information. 

Natural Langue Processing (NLP) is at the intersection of linguistics, computer science and humanities. After two months into the course, I have only further realized that in the modern age of digitalization, the interaction between computers and human languages are knitted tightly together. NLP really opened my mind to the extent of powerfulness that modern computer programs can be. For example, NLP models can understand and analyze contextual nuances that even some humans can't notice or comprehend, which to me is shocking since humans no longer are the experts of understanding and comprehending human languages. Various applications could be developed using NLP technology, such as document catagorization and organization, information extraction or filtering, speech recognition and beyond. As part of the reflection, I googled a lot of information about the history of the development of NLP.

From the The Georgetown experiment in 1954 that successfully translated over 60 russian sentences into English using fully automatic programs, NLPs have been progressing rapidly over the past few decades. Up until the 1980s, NLP technology has focused more on symbolic understanding and interpretation, which were fundamental to the further advancement of the technology and computer models. Sinece 1990, statistical NLP has taken the lead in the field of natural language processing. IBM Research hugely aided the progress through the implementation of machine learning-based translation systems. Moreover, statistical NLP has gradually evolved into neural NLP these days as other neural-based computer programs and theories have been applied to the field of NLP. For example, a very hot topic in NLP these days is called deep neural network, which Tufts teaches an entire course around the concept. NLP's business potential is also huge, for example, it has been widely used in the healthcare industry as the standard procedure for analyzing electronic health records content. Without a doubt, the tasks that NLPs can perform will no longer be limited to speech recognition or text to speech translation, it will further be developted to understand relational semantics and logical semantics too.
